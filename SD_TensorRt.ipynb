{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6GXo7CXnPuJ"
      },
      "source": [
        "https://www.cerebrium.ai/blog/improve-stable-diffusion-inference-by-50-with-tensorrt-or-aitemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRfDoBJAnPuN"
      },
      "source": [
        "Установим необходимые для работы библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OkXYXIynPuO",
        "outputId": "6435f610-ffb3-415c-eae2-5caee3899929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=f577fc74a121be2f6cbefa2aae73dc86807a545935dd74977a14cd0e32d21da0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/af/d0/7a12f82cab69f65d51107f48bcd6179e29b9a69a90546332b3\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17283 sha256=1617ed0f604f098bf9c428114ffcfd194e733cfe2b274e9ba7085a54adc96c92\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt, nvidia-tensorrt\n",
            "Successfully installed nvidia-tensorrt-99.0.0 tensorrt-8.6.1.post1\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2023.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2023.1-cp310-cp310-linux_x86_64.whl size=661205 sha256=b7507fc4132b6878f4adc95b6c94da281ec54dc047a107bafa0c70a7c6258f25\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/65/06/b997165edd2fd9690c3497ca54ea4485b571d7bd959c21c6c4\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.0 pycuda-2023.1 pytools-2023.1.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.24.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: diffusers, accelerate\n",
            "Successfully installed accelerate-0.25.0 diffusers-0.24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install setuptools pip --user\n",
        "\n",
        "!pip install nvidia-pyindex\n",
        "\n",
        "!pip install nvidia-tensorrt\n",
        "\n",
        "!pip install pycuda\n",
        "\n",
        "!pip install transformers diffusers scipy accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-eAk9xnPuP"
      },
      "source": [
        "SD состоит из трех частей:  \n",
        " - Variational autoencoder   \n",
        " - UNet  \n",
        " - CLIP text encoder   \n",
        "Поскольку 90% всего времени работы сети занимает UNet, то имеенеет смысл оптимизировать именно эту часть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8jBmW8inPuQ"
      },
      "source": [
        "Скачаем и распакуем UNet модель с huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJIJUufxnPuQ",
        "outputId": "f7efc827-087b-4da5-993f-26ef4b567149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-16 13:31:46--  https://huggingface.co/kamalkraj/stable-diffusion-v1-4-onnx/resolve/main/models.tar.gz\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/32/db/32dbcbc7a65fabe86a8cc5a1e7e461df46c92556ebe53adcf62dc0521861db09/c0dffa0cc37e080a0bf5c1d9bdc62fe7895cd13edcd4efb43a3ee25f387b6955?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27models.tar.gz%3B+filename%3D%22models.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1702992706&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjk5MjcwNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zMi9kYi8zMmRiY2JjN2E2NWZhYmU4NmE4Y2M1YTFlN2U0NjFkZjQ2YzkyNTU2ZWJlNTNhZGNmNjJkYzA1MjE4NjFkYjA5L2MwZGZmYTBjYzM3ZTA4MGEwYmY1YzFkOWJkYzYyZmU3ODk1Y2QxM2VkY2Q0ZWZiNDNhM2VlMjVmMzg3YjY5NTU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=lG6ZbXEb%7E5IVnpLfP3hREf2JBYt46ner8GX3SDdW8vL6bBjaaUIZW7aWdZXSDgEY3y0zW2DorUpqFOHf4p0KH2LCwAGTkXbNwh8WQ1la1poTX3IqnRjeiRP9CFI-FfIF2NBPKlB2uCz%7ETRQ-RKB5CXtKeYYopbZ%7EJsvLdMP-6KxZdEzDAL7ycbo6P1p1GZJGPv-9GV9mY7DWoHtFpVDSBYIHacTIFDt7ahFX4viFDPfpKdFxSjJNOlvBPEsz6yy%7EOCNGhYh2M5Zx26Za3BTbI%7EvCo15xkeUV6R9UPN0xcnfVgugGtrhtd-7QZEZLfVfTtZjRbcTATp7YiP5ZYeGJBg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-12-16 13:31:47--  https://cdn-lfs.huggingface.co/repos/32/db/32dbcbc7a65fabe86a8cc5a1e7e461df46c92556ebe53adcf62dc0521861db09/c0dffa0cc37e080a0bf5c1d9bdc62fe7895cd13edcd4efb43a3ee25f387b6955?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27models.tar.gz%3B+filename%3D%22models.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1702992706&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjk5MjcwNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zMi9kYi8zMmRiY2JjN2E2NWZhYmU4NmE4Y2M1YTFlN2U0NjFkZjQ2YzkyNTU2ZWJlNTNhZGNmNjJkYzA1MjE4NjFkYjA5L2MwZGZmYTBjYzM3ZTA4MGEwYmY1YzFkOWJkYzYyZmU3ODk1Y2QxM2VkY2Q0ZWZiNDNhM2VlMjVmMzg3YjY5NTU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=lG6ZbXEb%7E5IVnpLfP3hREf2JBYt46ner8GX3SDdW8vL6bBjaaUIZW7aWdZXSDgEY3y0zW2DorUpqFOHf4p0KH2LCwAGTkXbNwh8WQ1la1poTX3IqnRjeiRP9CFI-FfIF2NBPKlB2uCz%7ETRQ-RKB5CXtKeYYopbZ%7EJsvLdMP-6KxZdEzDAL7ycbo6P1p1GZJGPv-9GV9mY7DWoHtFpVDSBYIHacTIFDt7ahFX4viFDPfpKdFxSjJNOlvBPEsz6yy%7EOCNGhYh2M5Zx26Za3BTbI%7EvCo15xkeUV6R9UPN0xcnfVgugGtrhtd-7QZEZLfVfTtZjRbcTATp7YiP5ZYeGJBg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.69.103, 18.239.69.105, 18.239.69.115, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.69.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5621110050 (5.2G) [application/gzip]\n",
            "Saving to: ‘models.tar.gz’\n",
            "\n",
            "models.tar.gz       100%[===================>]   5.23G  37.1MB/s    in 3m 41s  \n",
            "\n",
            "2023-12-16 13:35:28 (24.2 MB/s) - ‘models.tar.gz’ saved [5621110050/5621110050]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/kamalkraj/stable-diffusion-v1-4-onnx/resolve/main/models.tar.gz\n",
        "\n",
        "!tar -xf models.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQU8_f7YnPuR"
      },
      "source": [
        "Теперь перековрертируем скаченную модель в формат для TensorRt из ONNX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVLV43IunPuR"
      },
      "source": [
        "Импортируем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vgI_xPqZnPuR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorrt as trt\n",
        "import os, sys, argparse\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht2kcF6_nPuS"
      },
      "source": [
        "Путь к начальной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-I3CqmAGnPuS"
      },
      "outputs": [],
      "source": [
        "onnx_model = \"./models/unet/1/unet.onnx\"\n",
        "engine_filename = \"unet_new.engine\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdOhLFvvnPuT"
      },
      "source": [
        "Сначала мы создаем TensorRt engine из ONNX модели и используем некоторые оптимизации, вроде того, что имзенеям такие параметры, как: precision mode, maximum batch size, and maximum workspace size  \n",
        "Затем мы сохраняем полученный TensorRt engine в файл."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e5LJ9nq6nPuT"
      },
      "outputs": [],
      "source": [
        "def convert_model():\n",
        "    batch_size = 1\n",
        "    # параметры картинки\n",
        "    height = 512\n",
        "    width = 512\n",
        "    latents_shape = (batch_size*2, 4, height // 8, width // 8)\n",
        "    embed_shape = (batch_size*2,64,768)\n",
        "    timestep_shape = (batch_size,)\n",
        "\n",
        "    TRT_LOGGER = trt.Logger(trt.Logger.INFO) # для логгирования инициализируем Logger у TensorRt\n",
        "    TRT_BUILDER = trt.Builder(TRT_LOGGER) # инициализируем билдер и передаем ему логгер\n",
        "    # EXPLICIT_BATCH : Specify that the network should be created with an explicit batch dimension.\n",
        "    TRT_NETWORK = TRT_BUILDER.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) # создвем сеть\n",
        "\n",
        "    onnx_parser = trt.OnnxParser(TRT_NETWORK, TRT_LOGGER) # инициализируем парсер onnx для чтения данных из файла\n",
        "    parse_success = onnx_parser.parse_from_file(onnx_model)\n",
        "    for idx in range(onnx_parser.num_errors): # проверяем на налицие ошибок при чтении\n",
        "        print(onnx_parser.get_error(idx))\n",
        "    if not parse_success:\n",
        "        sys.exit('ONNX model parsing failed')\n",
        "    print(\"Load Onnx model done\")\n",
        "\n",
        "    config = TRT_BUILDER.create_builder_config()\n",
        "    profile = TRT_BUILDER.create_optimization_profile()\n",
        "    profile.set_shape(\"sample\", latents_shape, latents_shape, latents_shape)\n",
        "    profile.set_shape(\"encoder_hidden_states\", embed_shape, embed_shape, embed_shape)\n",
        "    profile.set_shape(\"timestep\", timestep_shape, timestep_shape, timestep_shape)\n",
        "    config.add_optimization_profile(profile)\n",
        "\n",
        "    config.set_flag(trt.BuilderFlag.FP16)\n",
        "    serialized_engine = TRT_BUILDER.build_serialized_network(TRT_NETWORK, config)\n",
        "\n",
        "    # сохраняем TrT модель в файл\n",
        "    with open(engine_filename, 'wb') as f:\n",
        "        f.write(serialized_engine)\n",
        "    print(f'Engine is saved to {engine_filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNVOO9ZBnPuU",
        "outputId": "ca92425c-333c-486c-856d-126374a9cd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Onnx model done\n",
            "Engine is saved to unet_new.engine\n"
          ]
        }
      ],
      "source": [
        "# Конвертируем модель\n",
        "convert_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lpl22dSnPuU"
      },
      "source": [
        "Теперь воспользуемся полученной моделью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e366g-v4nPuU"
      },
      "source": [
        "Импортирем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pmW3304BnPuU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from diffusers import AutoencoderKL\n",
        "from diffusers import LMSDiscreteScheduler\n",
        "from torch import autocast\n",
        "import argparse\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdgXe517nPuU"
      },
      "source": [
        "Функция получения аргументов для сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lrqbV198nPuV"
      },
      "outputs": [],
      "source": [
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--prompt\",\n",
        "        default=\"Super Mario learning to fly in an airport, Painting by Leonardo Da Vinci\",\n",
        "        help=\"input prompt\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--trt_unet_save_path\",\n",
        "        default=\"./unet.engine\",\n",
        "        type=str,\n",
        "        help=\"TensorRT unet saved path\",\n",
        "    )\n",
        "    parser.add_argument(\"--batch_size\", default=1, type=int, help=\"batch size\")\n",
        "    parser.add_argument(\n",
        "        \"--img_size\", default=(512, 512), help=\"Unet input image size (h,w)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\", default=64, help=\"Maximum sequence length of input text\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--benchmark\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Running benchmark by average num iteration\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--n_iters\", default=50, help=\"Running benchmark by average num iteration\"\n",
        "    )\n",
        "\n",
        "    return parser.parse_args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbPVoV62nPuV"
      },
      "source": [
        "Построим класс для работы с моделью"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps3JwtUgnPuV"
      },
      "outputs": [],
      "source": [
        "from trt_model import TRTModel\n",
        "class TrtDiffusionModel:\n",
        "    def __init__(self, args):\n",
        "        self.device = torch.device(\"cuda\") # устанавливаем режим работы на графическом процессоре\n",
        "        self.unet = TRTModel(args.trt_unet_save_path) # указываем путь к сохраненной сети UNet\n",
        "        # Устанавливаем остальные параметры SD - дефолтными и неоптимизированными\n",
        "        # (См составные части SD)\n",
        "        self.vae = AutoencoderKL.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-2-1\", subfolder=\"vae\", use_auth_token=True\n",
        "        ).to(self.device)\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-2-1\", subfolder=\"tokenizer\", use_auth_token=True\n",
        "        )\n",
        "        self.text_encoder = CLIPTextModel.from_pretrained(\n",
        "            \"openai/clip-vit-large-patch14\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.scheduler = LMSDiscreteScheduler(\n",
        "            beta_start=0.00085,\n",
        "            beta_end=0.012,\n",
        "            beta_schedule=\"scaled_linear\",\n",
        "            num_train_timesteps=1000,\n",
        "        )\n",
        "\n",
        "    def predict(\n",
        "        self, prompts, num_inference_steps=50, height=512, width=512, max_seq_length=64\n",
        "    ):\n",
        "        guidance_scale = 7.5\n",
        "        batch_size = 1\n",
        "        text_input = self.tokenizer(\n",
        "            prompts,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_seq_length,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        text_embeddings = self.text_encoder(text_input.input_ids.to(self.device))[0]\n",
        "        uncond_input = self.tokenizer(\n",
        "            [\"\"] * batch_size,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_seq_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        uncond_embeddings = self.text_encoder(uncond_input.input_ids.to(self.device))[0]\n",
        "        text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "        latents = torch.randn((batch_size, 4, height // 8, width // 8)).to(self.device)\n",
        "        self.scheduler.set_timesteps(num_inference_steps)\n",
        "\n",
        "        latents = latents * self.scheduler.sigmas[0]\n",
        "        with torch.inference_mode(), autocast(\"cuda\"):\n",
        "            for i, t in tqdm(enumerate(self.scheduler.timesteps)):\n",
        "                latent_model_input = torch.cat([latents] * 2)\n",
        "                sigma = self.scheduler.sigmas[i]\n",
        "                latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "\n",
        "                # predict the noise residual\n",
        "                inputs = [\n",
        "                    latent_model_input,\n",
        "                    torch.tensor([t]).to(self.device),\n",
        "                    text_embeddings,\n",
        "                ]\n",
        "                noise_pred, duration = self.unet(inputs, timing=True)\n",
        "                noise_pred = torch.reshape(noise_pred[0], (batch_size * 2, 4, 64, 64))\n",
        "\n",
        "                # perform guidance\n",
        "                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "                noise_pred = noise_pred_uncond + guidance_scale * (\n",
        "                    noise_pred_text - noise_pred_uncond\n",
        "                )\n",
        "\n",
        "                # compute the previous noisy sample x_t -> x_t-1\n",
        "                latents = self.scheduler.step(noise_pred.cuda(), t, latents)[\n",
        "                    \"prev_sample\"\n",
        "                ]\n",
        "\n",
        "            # scale and decode the image latents with vae\n",
        "            latents = 1 / 0.18215 * latents\n",
        "            image = self.vae.decode(latents).sample\n",
        "        return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxv_Rc4HnPuW"
      },
      "source": [
        "Начинаем работать с самой моделью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yisw78Y4nPuW"
      },
      "source": [
        "Получаем аргументы и инициализируем с помощью их модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96jZ8SgtnPuW"
      },
      "outputs": [],
      "source": [
        "args = get_args()\n",
        "model = TrtDiffusionModel(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8R1B5EonPuW"
      },
      "source": [
        "Проверяем установлен ли флаг на бенчмарк и проводим проверку, если таковой установлен на True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ8OuSDgnPuW"
      },
      "outputs": [],
      "source": [
        "if args.benchmark:\n",
        "    n_iters = args.n_iters\n",
        "    # warm up\n",
        "    for i in range(3):\n",
        "        image = model.predict(\n",
        "            prompts=args.prompt,\n",
        "            num_inference_steps=50,\n",
        "            height=args.img_size[0],\n",
        "            width=args.img_size[1],\n",
        "            max_seq_length=args.max_seq_length,\n",
        "        )\n",
        "else:\n",
        "    n_iters = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXx5r_4XnPuX"
      },
      "source": [
        "Запускаем predict(...) модели с заданными параметрами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC7t1bTtnPuX"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "for i in tqdm(range(n_iters)):\n",
        "    image = model.predict(\n",
        "        prompts=args.prompt,\n",
        "        num_inference_steps=50,\n",
        "        height=args.img_size[0],\n",
        "        width=args.img_size[1],\n",
        "        max_seq_length=args.max_seq_length,\n",
        "    )\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eUm92OwnPuX"
      },
      "source": [
        "Выводим получившееся изображение и результаты по времени"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyoZpfcYnPuY"
      },
      "outputs": [],
      "source": [
        "if args.benchmark:\n",
        "    print(\"Average inference time is: \", (end - start) / n_iters)\n",
        "image = (image / 2 + 0.5).clamp(0, 1)\n",
        "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "images = (image * 255).round().astype(\"uint8\")\n",
        "pil_images = [Image.fromarray(image) for image in images]\n",
        "pil_images[0].save(\"image_generated.png\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}